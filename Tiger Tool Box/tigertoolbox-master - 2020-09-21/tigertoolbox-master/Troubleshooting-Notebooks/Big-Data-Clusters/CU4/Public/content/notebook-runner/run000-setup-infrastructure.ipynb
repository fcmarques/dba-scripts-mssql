{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "RUN000 - Setup Master Pool runner infrastructure\n",
                "================================================\n",
                "\n",
                "Description\n",
                "-----------\n",
                "\n",
                "Create the Big Data Cluster SQL Master Pool objects to enable saving\n",
                "results.\n",
                "\n",
                "NOTE: This notebook uses the Python kernel, not the SQL kernel, so that\n",
                "it can be run in a \u2018single click\u2019 on all machines. (The SQL kernel\n",
                "requires a PowerShell module to be installed, that can\u2019t be guaranteed\n",
                "to be present on all machines).\n",
                "\n",
                "### Parameters\n",
                "\n",
                "Passwords are generated for the Logins to enable metrics to be saved\n",
                "(insert\\_metrics) by the run002 notebook, and to be read by the Grafana\n",
                "dashboards. These Passwords are only used if the Logins do not already\n",
                "exist."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import secrets\n",
                "import string\n",
                "\n",
                "# Generate passwords\n",
                "#\n",
                "alphabet = string.ascii_letters + string.digits + string.punctuation\n",
                "\n",
                "os.environ[\"runner_insert_metric_password\"] = ''.join(secrets.choice(alphabet) for i in range(20)) # for a 20-character password\n",
                "os.environ[\"runner_db_reader_password\"] = ''.join(secrets.choice(alphabet) for i in range(20)) # for a 20-character password\n",
                "\n",
                "os.environ[\"runner_insert_metric_password\"] = os.environ[\"runner_insert_metric_password\"].replace('\"', \"-\").replace(\"'\", \"_\")\n",
                "os.environ[\"runner_db_reader_password\"] = os.environ[\"runner_db_reader_password\"].replace('\"', \"-\").replace(\"'\", \"_\")\n",
                "\n",
                "print(\"Passwords generated\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Common functions\n",
                "\n",
                "Define helper functions used in this notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "source": [
                "# Define `run` function for transient fault handling, suggestions on error, and scrolling updates on Windows\n",
                "import sys\n",
                "import os\n",
                "import re\n",
                "import json\n",
                "import platform\n",
                "import shlex\n",
                "import shutil\n",
                "import datetime\n",
                "\n",
                "from subprocess import Popen, PIPE\n",
                "from IPython.display import Markdown\n",
                "\n",
                "retry_hints = {} # Output in stderr known to be transient, therefore automatically retry\n",
                "error_hints = {} # Output in stderr where a known SOP/TSG exists which will be HINTed for further help\n",
                "install_hint = {} # The SOP to help install the executable if it cannot be found\n",
                "\n",
                "first_run = True\n",
                "rules = None\n",
                "debug_logging = False\n",
                "\n",
                "def run(cmd, return_output=False, no_output=False, retry_count=0):\n",
                "    \"\"\"Run shell command, stream stdout, print stderr and optionally return output\n",
                "\n",
                "    NOTES:\n",
                "\n",
                "    1.  Commands that need this kind of ' quoting on Windows e.g.:\n",
                "\n",
                "            kubectl get nodes -o jsonpath={.items[?(@.metadata.annotations.pv-candidate=='data-pool')].metadata.name}\n",
                "\n",
                "        Need to actually pass in as '\"':\n",
                "\n",
                "            kubectl get nodes -o jsonpath={.items[?(@.metadata.annotations.pv-candidate=='\"'data-pool'\"')].metadata.name}\n",
                "\n",
                "        The ' quote approach, although correct when pasting into Windows cmd, will hang at the line:\n",
                "        \n",
                "            `iter(p.stdout.readline, b'')`\n",
                "\n",
                "        The shlex.split call does the right thing for each platform, just use the '\"' pattern for a '\n",
                "    \"\"\"\n",
                "    MAX_RETRIES = 5\n",
                "    output = \"\"\n",
                "    retry = False\n",
                "\n",
                "    global first_run\n",
                "    global rules\n",
                "\n",
                "    if first_run:\n",
                "        first_run = False\n",
                "        rules = load_rules()\n",
                "\n",
                "    # When running `azdata sql query` on Windows, replace any \\n in \"\"\" strings, with \" \", otherwise we see:\n",
                "    #\n",
                "    #    ('HY090', '[HY090] [Microsoft][ODBC Driver Manager] Invalid string or buffer length (0) (SQLExecDirectW)')\n",
                "    #\n",
                "    if platform.system() == \"Windows\" and cmd.startswith(\"azdata sql query\"):\n",
                "        cmd = cmd.replace(\"\\n\", \" \")\n",
                "\n",
                "    # shlex.split is required on bash and for Windows paths with spaces\n",
                "    #\n",
                "    cmd_actual = shlex.split(cmd)\n",
                "\n",
                "    # Store this (i.e. kubectl, python etc.) to support binary context aware error_hints and retries\n",
                "    #\n",
                "    user_provided_exe_name = cmd_actual[0].lower()\n",
                "\n",
                "    # When running python, use the python in the ADS sandbox ({sys.executable})\n",
                "    #\n",
                "    if cmd.startswith(\"python \"):\n",
                "        cmd_actual[0] = cmd_actual[0].replace(\"python\", sys.executable)\n",
                "\n",
                "        # On Mac, when ADS is not launched from terminal, LC_ALL may not be set, which causes pip installs to fail\n",
                "        # with:\n",
                "        #\n",
                "        #    UnicodeDecodeError: 'ascii' codec can't decode byte 0xc5 in position 4969: ordinal not in range(128)\n",
                "        #\n",
                "        # Setting it to a default value of \"en_US.UTF-8\" enables pip install to complete\n",
                "        #\n",
                "        if platform.system() == \"Darwin\" and \"LC_ALL\" not in os.environ:\n",
                "            os.environ[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
                "\n",
                "    # When running `kubectl`, if AZDATA_OPENSHIFT is set, use `oc`\n",
                "    #\n",
                "    if cmd.startswith(\"kubectl \") and \"AZDATA_OPENSHIFT\" in os.environ:\n",
                "        cmd_actual[0] = cmd_actual[0].replace(\"kubectl\", \"oc\")\n",
                "\n",
                "    # To aid supportabilty, determine which binary file will actually be executed on the machine\n",
                "    #\n",
                "    which_binary = None\n",
                "\n",
                "    # Special case for CURL on Windows.  The version of CURL in Windows System32 does not work to\n",
                "    # get JWT tokens, it returns \"(56) Failure when receiving data from the peer\".  If another instance\n",
                "    # of CURL exists on the machine use that one.  (Unfortunately the curl.exe in System32 is almost\n",
                "    # always the first curl.exe in the path, and it can't be uninstalled from System32, so here we\n",
                "    # look for the 2nd installation of CURL in the path)\n",
                "    if platform.system() == \"Windows\" and cmd.startswith(\"curl \"):\n",
                "        path = os.getenv('PATH')\n",
                "        for p in path.split(os.path.pathsep):\n",
                "            p = os.path.join(p, \"curl.exe\")\n",
                "            if os.path.exists(p) and os.access(p, os.X_OK):\n",
                "                if p.lower().find(\"system32\") == -1:\n",
                "                    cmd_actual[0] = p\n",
                "                    which_binary = p\n",
                "                    break\n",
                "\n",
                "    # Find the path based location (shutil.which) of the executable that will be run (and display it to aid supportability), this\n",
                "    # seems to be required for .msi installs of azdata.cmd/az.cmd.  (otherwise Popen returns FileNotFound) \n",
                "    #\n",
                "    # NOTE: Bash needs cmd to be the list of the space separated values hence shlex.split.\n",
                "    #\n",
                "    if which_binary == None:\n",
                "        which_binary = shutil.which(cmd_actual[0])\n",
                "\n",
                "    if which_binary == None:\n",
                "        if user_provided_exe_name in install_hint and install_hint[user_provided_exe_name] is not None:\n",
                "            display(Markdown(f'HINT: Use [{install_hint[user_provided_exe_name][0]}]({install_hint[user_provided_exe_name][1]}) to resolve this issue.'))\n",
                "\n",
                "        raise FileNotFoundError(f\"Executable '{cmd_actual[0]}' not found in path (where/which)\")\n",
                "    else:   \n",
                "        cmd_actual[0] = which_binary\n",
                "\n",
                "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
                "\n",
                "    print(f\"START: {cmd} @ {start_time} ({datetime.datetime.utcnow().replace(microsecond=0)} UTC)\")\n",
                "    print(f\"       using: {which_binary} ({platform.system()} {platform.release()} on {platform.machine()})\")\n",
                "    print(f\"       cwd: {os.getcwd()}\")\n",
                "\n",
                "    # Command-line tools such as CURL and AZDATA HDFS commands output\n",
                "    # scrolling progress bars, which causes Jupyter to hang forever, to\n",
                "    # workaround this, use no_output=True\n",
                "    #\n",
                "\n",
                "    # Work around a infinite hang when a notebook generates a non-zero return code, break out, and do not wait\n",
                "    #\n",
                "    wait = True \n",
                "\n",
                "    try:\n",
                "        if no_output:\n",
                "            p = Popen(cmd_actual)\n",
                "        else:\n",
                "            p = Popen(cmd_actual, stdout=PIPE, stderr=PIPE, bufsize=1)\n",
                "            with p.stdout:\n",
                "                for line in iter(p.stdout.readline, b''):\n",
                "                    line = line.decode()\n",
                "                    if return_output:\n",
                "                        output = output + line\n",
                "                    else:\n",
                "                        if cmd.startswith(\"azdata notebook run\"): # Hyperlink the .ipynb file\n",
                "                            regex = re.compile('  \"(.*)\"\\: \"(.*)\"') \n",
                "                            match = regex.match(line)\n",
                "                            if match:\n",
                "                                if match.group(1).find(\"HTML\") != -1:\n",
                "                                    display(Markdown(f' - \"{match.group(1)}\": \"{match.group(2)}\"'))\n",
                "                                else:\n",
                "                                    display(Markdown(f' - \"{match.group(1)}\": \"[{match.group(2)}]({match.group(2)})\"'))\n",
                "\n",
                "                                    wait = False\n",
                "                                    break # otherwise infinite hang, have not worked out why yet.\n",
                "                        else:\n",
                "                            print(line, end='')\n",
                "                            if rules is not None:\n",
                "                                apply_expert_rules(line)\n",
                "\n",
                "        if wait:\n",
                "            p.wait()\n",
                "    except FileNotFoundError as e:\n",
                "        if install_hint is not None:\n",
                "            display(Markdown(f'HINT: Use {install_hint} to resolve this issue.'))\n",
                "\n",
                "        raise FileNotFoundError(f\"Executable '{cmd_actual[0]}' not found in path (where/which)\") from e\n",
                "\n",
                "    exit_code_workaround = 0 # WORKAROUND: azdata hangs on exception from notebook on p.wait()\n",
                "\n",
                "    if not no_output:\n",
                "        for line in iter(p.stderr.readline, b''):\n",
                "            try:\n",
                "                line_decoded = line.decode()\n",
                "            except UnicodeDecodeError:\n",
                "                # NOTE: Sometimes we get characters back that cannot be decoded(), e.g.\n",
                "                #\n",
                "                #   \\xa0\n",
                "                #\n",
                "                # For example see this in the response from `az group create`:\n",
                "                #\n",
                "                # ERROR: Get Token request returned http error: 400 and server \n",
                "                # response: {\"error\":\"invalid_grant\",# \"error_description\":\"AADSTS700082: \n",
                "                # The refresh token has expired due to inactivity.\\xa0The token was \n",
                "                # issued on 2018-10-25T23:35:11.9832872Z\n",
                "                #\n",
                "                # which generates the exception:\n",
                "                #\n",
                "                # UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 179: invalid start byte\n",
                "                #\n",
                "                print(\"WARNING: Unable to decode stderr line, printing raw bytes:\")\n",
                "                print(line)\n",
                "                line_decoded = \"\"\n",
                "                pass\n",
                "            else:\n",
                "\n",
                "                # azdata emits a single empty line to stderr when doing an hdfs cp, don't\n",
                "                # print this empty \"ERR:\" as it confuses.\n",
                "                #\n",
                "                if line_decoded == \"\":\n",
                "                    continue\n",
                "                \n",
                "                print(f\"STDERR: {line_decoded}\", end='')\n",
                "\n",
                "                if line_decoded.startswith(\"An exception has occurred\") or line_decoded.startswith(\"ERROR: An error occurred while executing the following cell\"):\n",
                "                    exit_code_workaround = 1\n",
                "\n",
                "                # inject HINTs to next TSG/SOP based on output in stderr\n",
                "                #\n",
                "                if user_provided_exe_name in error_hints:\n",
                "                    for error_hint in error_hints[user_provided_exe_name]:\n",
                "                        if line_decoded.find(error_hint[0]) != -1:\n",
                "                            display(Markdown(f'HINT: Use [{error_hint[1]}]({error_hint[2]}) to resolve this issue.'))\n",
                "\n",
                "                # apply expert rules (to run follow-on notebooks), based on output\n",
                "                #\n",
                "                if rules is not None:\n",
                "                    apply_expert_rules(line_decoded)\n",
                "\n",
                "                # Verify if a transient error, if so automatically retry (recursive)\n",
                "                #\n",
                "                if user_provided_exe_name in retry_hints:\n",
                "                    for retry_hint in retry_hints[user_provided_exe_name]:\n",
                "                        if line_decoded.find(retry_hint) != -1:\n",
                "                            if retry_count < MAX_RETRIES:\n",
                "                                print(f\"RETRY: {retry_count} (due to: {retry_hint})\")\n",
                "                                retry_count = retry_count + 1\n",
                "                                output = run(cmd, return_output=return_output, retry_count=retry_count)\n",
                "\n",
                "                                if return_output:\n",
                "                                    return output\n",
                "                                else:\n",
                "                                    return\n",
                "\n",
                "    elapsed = datetime.datetime.now().replace(microsecond=0) - start_time\n",
                "\n",
                "    # WORKAROUND: We avoid infinite hang above in the `azdata notebook run` failure case, by inferring success (from stdout output), so\n",
                "    # don't wait here, if success known above\n",
                "    #\n",
                "    if wait: \n",
                "        if p.returncode != 0:\n",
                "            raise SystemExit(f'Shell command:\\n\\n\\t{cmd} ({elapsed}s elapsed)\\n\\nreturned non-zero exit code: {str(p.returncode)}.\\n')\n",
                "    else:\n",
                "        if exit_code_workaround !=0 :\n",
                "            raise SystemExit(f'Shell command:\\n\\n\\t{cmd} ({elapsed}s elapsed)\\n\\nreturned non-zero exit code: {str(exit_code_workaround)}.\\n')\n",
                "\n",
                "    print(f'\\nSUCCESS: {elapsed}s elapsed.\\n')\n",
                "\n",
                "    if return_output:\n",
                "        return output\n",
                "\n",
                "def load_json(filename):\n",
                "    \"\"\"Load a json file from disk and return the contents\"\"\"\n",
                "\n",
                "    with open(filename, encoding=\"utf8\") as json_file:\n",
                "        return json.load(json_file)\n",
                "\n",
                "def load_rules():\n",
                "    \"\"\"Load any 'expert rules' from the metadata of this notebook (.ipynb) that should be applied to the stderr of the running executable\"\"\"\n",
                "\n",
                "    # Load this notebook as json to get access to the expert rules in the notebook metadata.\n",
                "    #\n",
                "    try:\n",
                "        j = load_json(\"run000-setup-infrastructure.ipynb\")\n",
                "    except:\n",
                "        pass # If the user has renamed the book, we can't load ourself.  NOTE: Is there a way in Jupyter, to know your own filename?\n",
                "    else:\n",
                "        if \"metadata\" in j and \\\n",
                "            \"azdata\" in j[\"metadata\"] and \\\n",
                "            \"expert\" in j[\"metadata\"][\"azdata\"] and \\\n",
                "            \"expanded_rules\" in j[\"metadata\"][\"azdata\"][\"expert\"]:\n",
                "\n",
                "            rules = j[\"metadata\"][\"azdata\"][\"expert\"][\"expanded_rules\"]\n",
                "\n",
                "            rules.sort() # Sort rules, so they run in priority order (the [0] element).  Lowest value first.\n",
                "\n",
                "            # print (f\"EXPERT: There are {len(rules)} rules to evaluate.\")\n",
                "\n",
                "            return rules\n",
                "\n",
                "def apply_expert_rules(line):\n",
                "    \"\"\"Determine if the stderr line passed in, matches the regular expressions for any of the 'expert rules', if so\n",
                "    inject a 'HINT' to the follow-on SOP/TSG to run\"\"\"\n",
                "\n",
                "    global rules\n",
                "\n",
                "    for rule in rules:\n",
                "        notebook = rule[1]\n",
                "        cell_type = rule[2]\n",
                "        output_type = rule[3] # i.e. stream or error\n",
                "        output_type_name = rule[4] # i.e. ename or name \n",
                "        output_type_value = rule[5] # i.e. SystemExit or stdout\n",
                "        details_name = rule[6]  # i.e. evalue or text \n",
                "        expression = rule[7].replace(\"\\\\*\", \"*\") # Something escaped *, and put a \\ in front of it!\n",
                "\n",
                "        if debug_logging:\n",
                "            print(f\"EXPERT: If rule '{expression}' satisfied', run '{notebook}'.\")\n",
                "\n",
                "        if re.match(expression, line, re.DOTALL):\n",
                "\n",
                "            if debug_logging:\n",
                "                print(\"EXPERT: MATCH: name = value: '{0}' = '{1}' matched expression '{2}', therefore HINT '{4}'\".format(output_type_name, output_type_value, expression, notebook))\n",
                "\n",
                "            match_found = True\n",
                "\n",
                "            display(Markdown(f'HINT: Use [{notebook}]({notebook}) to resolve this issue.'))\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "print('Common functions defined successfully.')\n",
                "\n",
                "# Hints for binary (transient fault) retry, (known) error and install guide\n",
                "#\n",
                "retry_hints = {'kubectl': ['A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'], 'azdata': ['Endpoint sql-server-master does not exist', 'Endpoint livy does not exist', 'Failed to get state for cluster', 'Endpoint webhdfs does not exist', 'Adaptive Server is unavailable or does not exist', 'Error: Address already in use']}\n",
                "error_hints = {'kubectl': [['no such host', 'TSG010 - Get configuration contexts', '../monitor-k8s/tsg010-get-kubernetes-contexts.ipynb'], ['No connection could be made because the target machine actively refused it', 'TSG056 - Kubectl fails with No connection could be made because the target machine actively refused it', '../repair/tsg056-kubectl-no-connection-could-be-made.ipynb']], 'azdata': [['azdata login', 'SOP028 - azdata login', '../common/sop028-azdata-login.ipynb'], ['The token is expired', 'SOP028 - azdata login', '../common/sop028-azdata-login.ipynb'], ['Reason: Unauthorized', 'SOP028 - azdata login', '../common/sop028-azdata-login.ipynb'], ['Max retries exceeded with url: /api/v1/bdc/endpoints', 'SOP028 - azdata login', '../common/sop028-azdata-login.ipynb'], ['Look at the controller logs for more details', 'TSG027 - Observe cluster deployment', '../diagnose/tsg027-observe-bdc-create.ipynb'], ['provided port is already allocated', 'TSG062 - Get tail of all previous container logs for pods in BDC namespace', '../log-files/tsg062-tail-bdc-previous-container-logs.ipynb'], ['Create cluster failed since the existing namespace', 'SOP061 - Delete a big data cluster', '../install/sop061-delete-bdc.ipynb'], ['Failed to complete kube config setup', 'TSG067 - Failed to complete kube config setup', '../repair/tsg067-failed-to-complete-kube-config-setup.ipynb'], ['Error processing command: \"ApiError', 'TSG110 - Azdata returns ApiError', '../repair/tsg110-azdata-returns-apierror.ipynb'], ['Error processing command: \"ControllerError', 'TSG036 - Controller logs', '../log-analyzers/tsg036-get-controller-logs.ipynb'], ['ERROR: 500', 'TSG046 - Knox gateway logs', '../log-analyzers/tsg046-get-knox-logs.ipynb'], ['Data source name not found and no default driver specified', 'SOP069 - Install ODBC for SQL Server', '../install/sop069-install-odbc-driver-for-sql-server.ipynb'], [\"Can't open lib 'ODBC Driver 17 for SQL Server\", 'SOP069 - Install ODBC for SQL Server', '../install/sop069-install-odbc-driver-for-sql-server.ipynb'], ['Control plane upgrade failed. Failed to upgrade controller.', 'TSG108 - View the controller upgrade config map', '../diagnose/tsg108-controller-failed-to-upgrade.ipynb']]}\n",
                "install_hint = {'kubectl': ['SOP036 - Install kubectl command line interface', '../install/sop036-install-kubectl.ipynb'], 'azdata': ['SOP063 - Install azdata CLI (using package manager)', '../install/sop063-packman-install-azdata.ipynb']}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get the Kubernetes namespace for the big data cluster\n",
                "\n",
                "Get the namespace of the Big Data Cluster use the kubectl command line\n",
                "interface .\n",
                "\n",
                "**NOTE:**\n",
                "\n",
                "If there is more than one Big Data Cluster in the target Kubernetes\n",
                "cluster, then either:\n",
                "\n",
                "-   set \\[0\\] to the correct value for the big data cluster.\n",
                "-   set the environment variable AZDATA\\_NAMESPACE, before starting\n",
                "    Azure Data Studio."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "source": [
                "# Place Kubernetes namespace name for BDC into 'namespace' variable\n",
                "\n",
                "if \"AZDATA_NAMESPACE\" in os.environ:\n",
                "    namespace = os.environ[\"AZDATA_NAMESPACE\"]\n",
                "else:\n",
                "    try:\n",
                "        namespace = run(f'kubectl get namespace --selector=MSSQL_CLUSTER -o jsonpath={{.items[0].metadata.name}}', return_output=True)\n",
                "    except:\n",
                "        from IPython.display import Markdown\n",
                "        print(f\"ERROR: Unable to find a Kubernetes namespace with label 'MSSQL_CLUSTER'.  SQL Server Big Data Cluster Kubernetes namespaces contain the label 'MSSQL_CLUSTER'.\")\n",
                "        display(Markdown(f'HINT: Use [TSG081 - Get namespaces (Kubernetes)](../monitor-k8s/tsg081-get-kubernetes-namespaces.ipynb) to resolve this issue.'))\n",
                "        display(Markdown(f'HINT: Use [TSG010 - Get configuration contexts](../monitor-k8s/tsg010-get-kubernetes-contexts.ipynb) to resolve this issue.'))\n",
                "        display(Markdown(f'HINT: Use [SOP011 - Set kubernetes configuration context](../common/sop011-set-kubernetes-context.ipynb) to resolve this issue.'))\n",
                "        raise\n",
                "\n",
                "print(f'The SQL Server Big Data Cluster Kubernetes namespace is: {namespace}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get the controller username and password\n",
                "\n",
                "Get the controller username and password from the Kubernetes Secret\n",
                "Store and place in the required AZDATA\\_USERNAME and AZDATA\\_PASSWORD\n",
                "environment variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "source": [
                "# Place controller secret in AZDATA_USERNAME/AZDATA_PASSWORD environment variables\n",
                "\n",
                "import os, base64\n",
                "\n",
                "os.environ[\"AZDATA_USERNAME\"] = run(f'kubectl get secret/controller-login-secret -n {namespace} -o jsonpath={{.data.username}}', return_output=True)\n",
                "os.environ[\"AZDATA_USERNAME\"] = base64.b64decode(os.environ[\"AZDATA_USERNAME\"]).decode('utf-8')\n",
                "\n",
                "os.environ[\"AZDATA_PASSWORD\"] = run(f'kubectl get secret/controller-login-secret -n {namespace} -o jsonpath={{.data.password}}', return_output=True)\n",
                "os.environ[\"AZDATA_PASSWORD\"] = base64.b64decode(os.environ[\"AZDATA_PASSWORD\"]).decode('utf-8')\n",
                "\n",
                "\n",
                "print(f\"Controller username '{os.environ['AZDATA_USERNAME']}' and password stored in environment variables\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create Kubernetes secrets and SQL logins\n",
                "\n",
                "Create a T/SQL Login to insert metrics (done in the run002 notebook),\n",
                "and read metrics from Grafana."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "def create_tsql_login_if_not_exists(name, password_env_var):\n",
                "    output = run(f\"\"\"azdata sql query -q \"SELECT COUNT(*) as login_exists FROM sys.syslogins where name = '##{name}##'\" \"\"\", return_output=True)\n",
                "\n",
                "    login_exists = bool(json.loads(output)[0][\"login_exists\"])\n",
                "\n",
                "    if not login_exists:\n",
                "\n",
                "        # Delete K8s secret if previously created\n",
                "        # \n",
                "        secret = run(f\"kubectl get secrets --field-selector metadata.name={name.replace('_', '-')}-secret -n {namespace} --no-headers -o jsonpath={{.items}}\", return_output=True)\n",
                "\n",
                "        if secret != \"[]\":\n",
                "            run(f\"kubectl delete secret {name.replace('_', '-')}-secret -n {namespace}\")\n",
                "\n",
                "        run(f\"\"\"kubectl create secret generic {name.replace('_', '-')}-secret -n {namespace} --from-literal=username=##{name}## --from-literal=password={os.environ[password_env_var]}\"\"\")\n",
                "\n",
                "        sql = f\"\"\"CREATE LOGIN ##{name}## WITH PASSWORD = '{os.environ[password_env_var]}'\"\"\"\n",
                "\n",
                "        run(f'azdata sql query --database master -q \"{sql}\"')\n",
                "\n",
                "        # Clear out the password\n",
                "        #\n",
                "        os.environ[password_env_var] = \"\"\n",
                "\n",
                "create_tsql_login_if_not_exists('runner_insert_metric_login', \"runner_insert_metric_password\")\n",
                "create_tsql_login_if_not_exists('runner_db_reader_login', \"runner_db_reader_password\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create the `runner` database\n",
                "\n",
                "The metrics will be held in a database named `runner`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "IF DB_ID('runner') IS NULL\n",
                "BEGIN\n",
                "  CREATE DATABASE [runner]\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database master -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create the SQL tables\n",
                "\n",
                "Create the required T/SQL tables to hold the metrics. The schema is\n",
                "normalized to optimize performance (dense records), and views are\n",
                "provided to consume the data in dashboards.\n",
                "\n",
                "-   `tbl_notebook` \u2013 generates an internal `id` for each notebook file\n",
                "    name received\n",
                "-   `tbl_app` \u2013 generates an internal `id` for each \u2018app-deploy\u2019 app\n",
                "    name/version received. It also notes if the app-deploy is used as a\n",
                "    canary (to enable dashboards to optimize displays)\n",
                "-   `tbl_session` \u2013 generate an `id` for each session. A session is a\n",
                "    single invocation of all the notebooks in an app-deploy.\n",
                "-   `tbl_metrics` \u2013 the fully normalized table containing all the\n",
                "    metrics of notebook execution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "IF NOT EXISTS (SELECT *\n",
                "              FROM INFORMATION_SCHEMA.TABLES\n",
                "              WHERE TABLE_SCHEMA = 'dbo'\n",
                "              AND TABLE_NAME = 'tbl_notebook')\n",
                "BEGIN\n",
                "    CREATE TABLE [dbo].[tbl_notebook](\n",
                "        [id] [int] NOT NULL IDENTITY,\n",
                "        [name] [sysname] NOT NULL,\n",
                "        [created] [datetime2](7) NOT NULL DEFAULT GETDATE()\n",
                "        CONSTRAINT [PK__notebook__id] PRIMARY KEY CLUSTERED \n",
                "        (\n",
                "            [id] ASC\n",
                "        )\n",
                "    )\n",
                "END\n",
                "\n",
                "IF NOT EXISTS (SELECT *\n",
                "              FROM INFORMATION_SCHEMA.TABLES\n",
                "              WHERE TABLE_SCHEMA = 'dbo'\n",
                "              AND TABLE_NAME = 'tbl_app')\n",
                "BEGIN\n",
                "    CREATE TABLE [dbo].[tbl_app](\n",
                "        [id] [int] NOT NULL IDENTITY,\n",
                "        [name] [sysname] NOT NULL,\n",
                "        [version] [sysname] NOT NULL,\n",
                "        [is_canary] [bit] NOT NULL,\n",
                "        [created] [datetime2](7) NOT NULL DEFAULT GETDATE()\n",
                "        CONSTRAINT [PK__app__id] PRIMARY KEY CLUSTERED \n",
                "        (\n",
                "            [id] ASC\n",
                "        )\n",
                "    )\n",
                "END\n",
                "\n",
                "IF NOT EXISTS (SELECT *\n",
                "              FROM INFORMATION_SCHEMA.TABLES\n",
                "              WHERE TABLE_SCHEMA = 'dbo'\n",
                "              AND TABLE_NAME = 'tbl_session')\n",
                "BEGIN\n",
                "    CREATE TABLE [dbo].[tbl_session](\n",
                "        [id] [int] NOT NULL IDENTITY,\n",
                "        [start] [datetime2](7) NOT NULL,\n",
                "        [app_id] [int] NOT NULL CONSTRAINT FK__session__app_id FOREIGN KEY REFERENCES [dbo].[tbl_app](id) ON DELETE CASCADE\n",
                "        CONSTRAINT [PK__session__id] PRIMARY KEY CLUSTERED \n",
                "        (\n",
                "            [id] ASC\n",
                "        )\n",
                "    )\n",
                "END\n",
                "\n",
                "IF NOT EXISTS (SELECT *\n",
                "              FROM INFORMATION_SCHEMA.TABLES\n",
                "              WHERE TABLE_SCHEMA = 'dbo'\n",
                "              AND TABLE_NAME = 'tbl_metrics')\n",
                "BEGIN\n",
                "    CREATE TABLE [dbo].[tbl_metrics](\n",
                "        [session_id] [int] NOT NULL CONSTRAINT FK__metrics__session_id FOREIGN KEY REFERENCES [dbo].[tbl_session](id) ON DELETE CASCADE,\n",
                "        [step] [tinyint] NOT NULL,\n",
                "        [notebook_id] [int] NOT NULL CONSTRAINT FK__metrics__notebook_id FOREIGN KEY REFERENCES [dbo].[tbl_notebook](id) ON DELETE CASCADE,\n",
                "        [error_level] [tinyint] NOT NULL,\n",
                "        [base_notebook_id] [int] NULL CONSTRAINT FK__metrics__base_notebook_id FOREIGN KEY REFERENCES [dbo].[tbl_notebook](id),\n",
                "        [parent_notebook_id] [int] NULL CONSTRAINT FK__metrics__parent_notebook_id FOREIGN KEY REFERENCES [dbo].[tbl_notebook](id),\n",
                "        [html_notebook_included] [bit] NOT NULL,\n",
                "        [start] [datetime2](7) NOT NULL,\n",
                "        [end] [datetime2](7) NOT NULL\n",
                "        CONSTRAINT [PK__metrics__session_id__start] PRIMARY KEY CLUSTERED \n",
                "        (\n",
                "            [session_id] ASC,\n",
                "            [start] ASC\n",
                "        )\n",
                "    )\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create `insert_metric` procedure\n",
                "\n",
                "The `insert metric` procedure is called from the run002 notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "CREATE OR ALTER PROCEDURE [dbo].[insert_metric]\n",
                "    @session_start DATETIME2, \n",
                "    @app_name SYSNAME,\n",
                "    @app_version SYSNAME,\n",
                "    @step TINYINT,\n",
                "    @notebook_name NVARCHAR(max),\n",
                "    @error_level TINYINT,\n",
                "    @base_notebook_name NVARCHAR(max),\n",
                "    @parent_notebook_name NVARCHAR(max),\n",
                "    @html_notebook_included BIT,\n",
                "    @start DATETIME2,\n",
                "    @end DATETIME2\n",
                "AS\n",
                "BEGIN\n",
                "    SET NOCOUNT ON\n",
                "    SET XACT_ABORT ON\n",
                "    BEGIN TRAN\n",
                "\n",
                "        /* Get the app_id from the app_name/app_version */\n",
                "        DECLARE @app_id INT = (SELECT id FROM [dbo].[tbl_app] WHERE [name] = @app_name AND [version] = @app_version)\n",
                "        IF @app_id IS NULL\n",
                "        BEGIN\n",
                "            INSERT INTO [dbo].[tbl_app] VALUES (@app_name, @app_version, 0, DEFAULT)\n",
                "            SET @app_id = SCOPE_IDENTITY()\n",
                "        END\n",
                "\n",
                "        /* Get the session_id from the session_start/app_name/app_version */\n",
                "        DECLARE @session_id INT = (SELECT id FROM [dbo].[tbl_session] WHERE [start] = @session_start and [app_id] = @app_id)\n",
                "        IF @session_id IS NULL\n",
                "        BEGIN\n",
                "            INSERT INTO [dbo].[tbl_session] VALUES (@session_start, @app_id)\n",
                "            SET @session_id = SCOPE_IDENTITY()\n",
                "        END\n",
                "\n",
                "        /* Get the notebook_id for the notebook_name */\n",
                "        DECLARE @notebook_id INT = (SELECT id FROM [dbo].[tbl_notebook] WHERE [name] = @notebook_name)\n",
                "        IF @notebook_id IS NULL\n",
                "        BEGIN\n",
                "            INSERT INTO [dbo].[tbl_notebook] VALUES (@notebook_name, DEFAULT)\n",
                "            SET @notebook_id = SCOPE_IDENTITY()\n",
                "        END\n",
                "\n",
                "        /* Get the notebook_id for the base_notebook_name */\n",
                "        DECLARE @base_notebook_id INT = NULL\n",
                "        IF @base_notebook_name <> ''\n",
                "        BEGIN\n",
                "            SET @base_notebook_id = (SELECT id FROM [dbo].[tbl_notebook] WHERE [name] = @base_notebook_name)\n",
                "            IF @base_notebook_id IS NULL\n",
                "            BEGIN\n",
                "                INSERT INTO [dbo].[tbl_notebook] VALUES (@base_notebook_name, DEFAULT)\n",
                "                SET @base_notebook_id = SCOPE_IDENTITY()\n",
                "            END\n",
                "        END\n",
                "\n",
                "        /* Get the notebook_id for the parent_notebook_name */\n",
                "        DECLARE @parent_notebook_id INT = NULL\n",
                "        IF @parent_notebook_name <> ''\n",
                "        BEGIN\n",
                "            SET @parent_notebook_id = (SELECT id FROM [dbo].[tbl_notebook] WHERE [name] = @parent_notebook_name)\n",
                "            IF @parent_notebook_id IS NULL\n",
                "            BEGIN\n",
                "                INSERT INTO [dbo].[tbl_notebook] VALUES (@parent_notebook_name, DEFAULT)\n",
                "                SET @parent_notebook_id = SCOPE_IDENTITY()\n",
                "            END\n",
                "        END\n",
                "\n",
                "        INSERT [dbo].[tbl_metrics] VALUES(@session_id, @step, @notebook_id, @error_level, @base_notebook_id, @parent_notebook_id, @html_notebook_included, @start, @end)\n",
                "\n",
                "    COMMIT\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create views\n",
                "\n",
                "These views are used to power the Grafana dashboards"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "CREATE OR ALTER VIEW [dbo].[sessions]\n",
                "AS\n",
                "    SELECT s.id, s.start as session_start, a.name as app_name, a.version as app_version, a.is_canary\n",
                "    FROM [dbo].[tbl_session] s\n",
                "    JOIN [dbo].[tbl_app] a ON s.app_id = a.id\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "CREATE OR ALTER VIEW [dbo].[metrics]\n",
                "AS\n",
                "    SELECT \n",
                "        s.[session_start],\n",
                "        s.[app_name], \n",
                "        s.[app_version],\n",
                "        m.[step],\n",
                "        n.[name],\n",
                "        m.[error_level],\n",
                "        p.[name] as [parent_name],\n",
                "        m.[start],\n",
                "        m.[end],\n",
                "        'app-deploy/' + /* Build up the URL to this notebook in HDFS */\n",
                "            s.[app_name] + '-' + s.[app_version] +\n",
                "            '/logs/' +\n",
                "            FORMAT(DATEPART(yy, s.[session_start]),'D4') + '/' +\n",
                "            FORMAT(DATEPART(mm, s.[session_start]),'D2') + '/' +\n",
                "            FORMAT(DATEPART(dd, s.[session_start]),'D2') + '/' +\n",
                "            FORMAT(DATEPART(hh, s.[session_start]),'D2') + '-' +\n",
                "            FORMAT(DATEPART(mi, s.[session_start]),'D2') + '-' +\n",
                "            CASE m.[error_level] WHEN 0 THEN 'SUCCESS-' ELSE 'FAILURE-' END + \n",
                "            'step' + FORMAT(m.[step],'D3') + '-' +\n",
                "            n.[name] +\n",
                "            CASE m.html_notebook_included WHEN 1 THEN '.html' ELSE '.ipynb' END as [notebook]\n",
                "    FROM dbo.tbl_metrics m\n",
                "    JOIN dbo.sessions s on m.session_id = s.id\n",
                "    JOIN dbo.tbl_notebook n on m.notebook_id = n.id\n",
                "    LEFT OUTER JOIN dbo.tbl_notebook p on m.parent_notebook_id = p.id\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create canary\\_stats function\n",
                "\n",
                "Grafana dashboard don\u2019t work with CTEs (Common Table Expressions),\n",
                "therefore creating Functions here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "CREATE OR ALTER FUNCTION canary_stats (@hours INT)\n",
                "RETURNS TABLE\n",
                "AS\n",
                "RETURN\n",
                "    WITH last_hours([app_name], [passed], [failed])\n",
                "    AS\n",
                "    (\n",
                "        SELECT  [app_name],\n",
                "            (SELECT count(*) FROM [metrics] r2 WHERE r1.app_name = r2.app_name AND r2.error_level = 0 AND app_name LIKE 'canary-%' AND start > DATEADD(hour, @hours, GETDATE())) AS [passed],\n",
                "            (SELECT count(*) FROM [metrics] r2 WHERE r1.app_name = r2.app_name AND r2.error_level <> 0 AND app_name LIKE 'canary-%' AND start > DATEADD(hour, @hours, GETDATE())) AS [failed]\n",
                "        FROM [metrics] r1\n",
                "        WHERE app_name LIKE 'canary-%' AND start > DATEADD(hour, @hours, GETDATE())\n",
                "        GROUP BY [app_name]\n",
                "    )\n",
                "    SELECT [app_name] as Canary, [Passed], [Failed], [passed] + [failed] as Total, CONVERT(DECIMAL(5, 2), ([passed] * 1.0) / ([passed] + [failed]) * 100.0) as [Percent]\n",
                "    FROM last_hours\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create maintenance procs\n",
                "\n",
                "Use these procs to clear up the runner database:\n",
                "\n",
                "-   `delete_app_metrics` \u2013 if there is an app you no longer want to\n",
                "    appear in dashboards."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "CREATE OR ALTER PROCEDURE [dbo].[delete_app_metrics]\n",
                "    @app_name SYSNAME,\n",
                "    @app_version SYSNAME\n",
                "AS\n",
                "BEGIN\n",
                "    SET NOCOUNT ON\n",
                "    SET XACT_ABORT ON\n",
                "    BEGIN TRAN\n",
                "        DELETE [dbo].[tbl_app] WHERE name = @app_name and version = @app_version\n",
                "    COMMIT\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')\n",
                "\n",
                "sql = f\"\"\"\n",
                "CREATE OR ALTER PROCEDURE [dbo].[delete_notebook_metrics] @name SYSNAME AS\n",
                "BEGIN\n",
                "    SET NOCOUNT ON\n",
                "    SET XACT_ABORT ON \n",
                "    \n",
                "    BEGIN TRAN\n",
                "        DECLARE @notebook_id INT = (SELECT id FROM tbl_notebook WHERE name = @name)\n",
                "\n",
                "        /* Update self referencing columns to NULL, to allow DELETE CASCASE */\n",
                "        UPDATE tbl_metrics\n",
                "        SET parent_notebook_id = NULL \n",
                "        WHERE parent_notebook_id = @notebook_id\n",
                "\n",
                "        UPDATE tbl_metrics\n",
                "        SET base_notebook_id = NULL \n",
                "        WHERE base_notebook_id = @notebook_id\n",
                "\n",
                "        DELETE [dbo].[tbl_notebook] WHERE name = @name     \n",
                "    COMMIT\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Set up permissions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = f\"\"\"\n",
                "IF NOT EXISTS (SELECT * FROM sys.sysusers WHERE name = '##runner_db_reader_login##')\n",
                "BEGIN\n",
                "    CREATE USER ##runner_db_reader_login## FOR LOGIN ##runner_db_reader_login##\n",
                "    ALTER ROLE db_datareader ADD MEMBER ##runner_db_reader_login##\n",
                "END\n",
                "\n",
                "IF NOT EXISTS (SELECT * FROM sys.sysusers WHERE name = '##runner_insert_metric_login##')\n",
                "BEGIN\n",
                "    CREATE USER ##runner_insert_metric_login## FOR LOGIN ##runner_insert_metric_login##\n",
                "    GRANT CONNECT TO [##runner_insert_metric_login##]\n",
                "    GRANT EXECUTE ON [dbo].[insert_metric] TO [##runner_insert_metric_login##]\n",
                "END\n",
                "\"\"\"\n",
                "\n",
                "run(f'azdata sql query --database runner -q \"{sql}\"')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Notebook execution complete.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Related\n",
                "-------\n",
                "\n",
                "-   [RUN003 - Run expert\n",
                "    rules](../notebook-runner/run003-run-expert-rules.ipynb)\n",
                "\n",
                "-   [OPR001 - Create\n",
                "    app-deploy](../notebook-o16n/opr001-create-app-deploy.ipynb)\n",
                "\n",
                "-   [OPR600 - Monitor infrastructure\n",
                "    (Kubernetes)](../notebook-o16n/opr600-monitor-infrastructure-k8s.ipynb)\n",
                "\n",
                "-   [OPR900 - Troubleshoot run\n",
                "    app-deploy](../notebook-o16n/opr900-troubleshoot-run-app-deploy.ipynb)\n",
                "\n",
                "-   [RUN999 - Cleanup Master Pool runner\n",
                "    infrastructure](../notebook-runner/run999-cleanup-infrastructure.ipynb)"
            ]
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "azdata": {
            "side_effects": true,
            "symlink": true
        }
    }
}